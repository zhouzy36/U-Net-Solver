# U-Net PDE Solver

## 简介

UNet是一种具有编码器-解码器结构的卷积神经网络，最初被用于医学图像分割任务，并随后被广泛应用于多种图像到图像的任务，如图像的超分辨率和在扩散模型中的去噪。近年来，UNet也开始被用于解决偏微分方程相关的问题。

在将UNet应用于PDE求解中，通常会仿照传统的数值方法，将PDE的求解空间域离散化为多个网格。此时，方程在每个时刻 $t$​ 的解可以被视为一张图像，解函数在每个位置处的值可以被视为图像的像素值。因此，可以利用UNet学习从已知时刻的解到未知时刻的解的映射来求解偏微分方程问题。 UNet的能力在于通过学习从已知的空间域解到未知时刻的解之间的映射关系，实现对复杂偏微分方程的高效求解。

### 模型结构

![UNet模型结构](README.assets/UNet模型结构.png)

### 求解框架

UNet基于方程前 $l$ 个时间步的解 ${\hat{u}^{k-l+1},...,\hat{u}^k}$ 预测下一个时间步 $\hat{u}^{k+1}$ 的解，该过程可以公式化为：
$$
\hat{u}^{k+1} = \text{U-Net}(\hat{u}^{k-l+1:k};\theta).
$$

在推理时时，前 $l$ 个时间步的解表示为 $\{u^0,...,u^{l-1}\}$，由高精度数值方法生成，它们是模型的初始输入。其余时间步的解由模型自回归地生成（即其余时间步的输入会包括模型的预测值）。

### 损失函数

将UNet模型记作 $f_{\theta}$ ，$\theta$ 为模型可学习的参数，模型基于前 $l$ 个时间步的解 ${\hat{u}^{k-l+1},...,\hat{u}^k}$ 预测下一个时间步 $\hat{u}^{k+1}$ 的解：
$$
\hat{u}^{k+1} = f_{\theta}(\hat{u}^{k-l+1},...,\hat{u}^k).
$$

损失函数的一般形式为：
$$
\mathcal{L}=\frac{1}{N}\sum_{k=0}^{N-1}\mathcal{L}_{\text{data}}(f_{\theta}(\hat{u}^{k-l+1},...,\hat{u}^k), u^{k+1})
$$

其中 $u^{k+1}$ 是由高阶数值方法生成的，$\mathcal{L}_{\text{data}}$​ 可以是均方误差（Mean Squared Error，MSE）和均方根误差（Root Mean Squared Error，RMSE）等用于衡量模型预测值与真实值之间误差程度的损失函数。在本实现中，我们使用MSE作为损失函数。

### 训练方法

假设一个空间维度为2的方程真解数据形状为 $(N_t, N_x, N_y, N_d)$，$N_t$为时间步的步数（也称作时间分辨率），$N_x,N_y$为空间沿$x$和沿$y$方向的采样点的个数（$N_x \times N_y$也称为空间分辨率），$N_d$为方程待求解的变量个数。训练时，取前 $l$ 个时刻的解作为模型的输入，输入resize为形状 $(l\times N_d,N_x,N_y)$ 的tensor，类似图片的$(C,H,W)$。模型输出的形状为 $(N_d, N_x, N_y)$，表示第 $(l+1)$ 时刻 $N_d$ 个变量在空间域上的解。根据每次输入模型的数据是否为真实数据，可以将训练方法分为单步训练法和自回归训练：

**单步训练**：每次模型的输入总是来自数据集（ground truth），每一步推理的损失可以写作：
$$
\mathcal{L}_{\text{single}}=\mathcal{L}_{\text{data}}(f_{\theta}(u^{k-l+1},...,u^k), u^{k+1}).
$$

如果推理了$(N_t-l)$ 次，累积平均损失可以写作：


$$
\mathcal{L}=\frac{1}{N}\sum_{k=0}^{N_t-l}\mathcal{L}_{\text{single}}=\frac{1}{N}\sum_{k=0}^{N_t-l}\mathcal{L}_{\text{data}}(f_{\theta}(u^{k-l+1},...,u^k), u^{k+1}).
$$

**自回归训练**：只有第一次模型的输入来自数据集，剩下的输入由模型推理得到。因此，推理了$(N_t-l)$ 次的累积平均损失可以写作：
$$
\mathcal{L}=\frac{1}{N}\sum_{k=0}^{N_t-l}\mathcal{L}_{\text{data}}(f_{\theta}(\hat{u}^{k-l+1},...,\hat{u}^k), u^{k+1})
$$

## 快速开始

### 数据准备

### 配置文件

### 训练

### 测试

## 结果可视化

## 引用